# BUILD-SEQUENCE.md — Claude Code Implementation Guide

> **Purpose**: This document tells Claude Code HOW to build BoardClaude. It is loaded
> at the start of the hackathon (minute 12) and provides an ordered implementation
> plan with dependencies, context loading instructions, and verification checkpoints.
>
> **Audience**: Claude Code (not Oscar). Written as direct instructions.
>
> **Scope**: Covers M1 (First Audit, hours 0-6) and M2 (Closed Loop, hours 6-18).
> Later milestones are driven by CLAUDE.md and the GO-LIVE-RUNBOOK.

---

## Context Loading Rules

Do NOT load all 57 prep-kit files. Load only what's needed for the current phase.

| Phase | Load These Files | Do NOT Load |
|-------|-----------------|-------------|
| Phase 1 (Types) | `context/architecture/schemas.md` | Everything else in context/ |
| Phase 2 (Plugin Wiring) | `.claude-plugin/plugin.json`, `hooks/hooks.json` | Agent personas, strategy docs |
| Phase 3 (Validation Runner) | `skills/validation-runner/SKILL.md` | Other skills |
| Phase 4 (Audit Pipeline) | `commands/audit.md`, `skills/audit-runner/SKILL.md`, `panels/hackathon-judges.yaml` | Context/judges/, context/features/ |
| Phase 5 (Agent Orchestration) | `agents/boris.md` (as reference), `agents/synthesis.md` | Other judge dossiers in context/judges/ |
| Phase 6 (Self-Audit #0) | `.boardclaude/` state files (generated by now) | Strategy docs, demo docs |

**Always loaded**: `CLAUDE.md` (automatic), this file.

---

## Phase 1: TypeScript Foundation (Minutes 12-30)

**Goal**: Define all data types. Everything else depends on these.

**Create**: `dashboard/lib/types.ts`

Define interfaces for every schema in `context/architecture/schemas.md`:

1. `AgentEvaluation` — per-agent output (Section 3 of schemas.md)
   - scores: Record<string, number>
   - composite: number
   - strengths, weaknesses, critical_issues: string[]
   - action_items: Array<{ priority, action, impact }>
   - verdict: 'STRONG_PASS' | 'PASS' | 'MARGINAL' | 'FAIL'
   - one_line: string

2. `SynthesisReport` — full audit output (Section 4)
   - audit_id, panel, target, iteration, timestamp
   - agents: AgentEvaluation[]
   - composite: { score, radar: Record<string, number>, grade, verdict }
   - highlights: { top_strengths, top_weaknesses, divergent_opinions }
   - action_items: Array<{ priority, action, source_agent, impact, effort }>
   - iteration_delta: { previous_score, current_score, delta, improvements, regressions }

3. `PanelConfig` — parsed panel YAML (Section 2)
   - name, type, version, description
   - agents: Array<{ name, role, weight, model, effort, veto_power, prompt_file, criteria }>
   - scoring: { scale, passing_threshold, iteration_target }

4. `ProjectState` — state.json (Section 5)
   - project, panel, branch, audit_count, latest_audit, latest_score
   - score_history: number[]
   - worktrees: string[]
   - status: 'idle' | 'active' | 'auditing'

5. `TimelineEvent` — timeline.json events (Section 6)
   - id, type, timestamp, branch, parent, status
   - Union type for audit/fork/merge/rollback event variants

6. `ActionItem` — action-items.json items (Section 10)
   - id, source_audit, source_agent, action, file_refs
   - priority, effort, status, resolved_in_audit, iterations_open

7. `ValidationResult` — validation output (Section 11)
   - typescript, tests, lint, format, lighthouse sections
   - Each with skipped flag, counts, details arrays

**Verify**: `npx tsc --noEmit` passes with 0 errors on the types file.

---

## Phase 2: Plugin Wiring (Minutes 30-45)

**Goal**: Ensure Claude Code recognizes BoardClaude as a plugin with working commands.

**Verify plugin structure**:
```
boardclaude/
├── .claude-plugin/plugin.json    ← already copied from prep-kit
├── agents/*.md                   ← already copied
├── commands/*.md                 ← already copied
├── skills/*/SKILL.md             ← already copied
├── panels/*.yaml                 ← already copied
├── hooks/hooks.json              ← already copied
└── dashboard/                    ← Next.js scaffold from go-live
```

**Test**: Run `claude` and verify that `/bc:audit` is recognized as a command. If not, check:
- `.claude-plugin/plugin.json` `commands` field points to `./commands/`
- Command files have `$ARGUMENTS` placeholder at the end
- Plugin name in `plugin.json` matches expected namespace

**No code to write here** — this is verification that the go-live copy step worked.

---

## Phase 3: Validation Runner (Minutes 45-90)

**Goal**: Build the validation-runner skill so agents have real data.

**Why first**: The audit pipeline needs validation data to feed to agents. Without it, agents evaluate blind. Building this first means every audit from Self-Audit #0 onward has real data.

**Read**: `skills/validation-runner/SKILL.md` — it has the complete specification.

**Create**: `skills/validation-runner/run.ts` (or implement inline in the skill)

The validation-runner is a Bash-heavy skill. Implementation:

1. Detect stack from `package.json` (framework, language, test runner, linter, formatter)
2. Run `npx tsc --noEmit` → parse error/warning counts
3. Run `npm test -- --reporter=json` → parse pass/fail/coverage
4. Run `npx next lint --format=json` → parse lint errors/warnings
5. Run `npx prettier --check .` → calculate compliance percentage
6. Assemble into `ValidationResult` JSON
7. Save to `.boardclaude/validation/latest.json`

**Key details**:
- Each command gets a 60-second timeout
- Missing tools get `skipped: true`, not failures
- Test failure (exit code 1) is expected — parse the output
- Cap details arrays at 10 entries

**Verify**: Run validation-runner manually against the dashboard/ project. It should produce a valid `latest.json` even if everything is empty (new scaffold).

---

## Phase 4: Audit Pipeline Core (Minutes 90-180)

**Goal**: Build the `/bc:audit` command end-to-end with a single agent first, then expand.

**Read**: `commands/audit.md` (flow), `skills/audit-runner/SKILL.md` (orchestration), `panels/hackathon-judges.yaml` (config).

### Step 4a: YAML Parser + State Initialization

Create utility to:
- Parse panel YAML into `PanelConfig` type
- Initialize `.boardclaude/` directory structure (state.json, timeline.json, audits/)
- Read/update state.json

### Step 4b: Single-Agent Audit (Boris only)

Before attempting 6-agent parallelism, get one agent working:
1. Load panel config → extract Boris's entry
2. Load `agents/boris.md` persona
3. Read validation `latest.json` for data context
4. Spawn a **single subagent** with Boris's persona + codebase + validation data
5. Parse the returned JSON into `AgentEvaluation`
6. Verify the output matches the schema

**This is the critical checkpoint.** If a single agent produces valid JSON evaluation output, the rest is orchestration.

### Step 4c: Synthesis (single-agent input)

1. Load `agents/synthesis.md`
2. Feed Boris's evaluation to the synthesis agent
3. Verify it produces valid `SynthesisReport` JSON
4. Save to `.boardclaude/audits/audit-{timestamp}.json`
5. Update `state.json` and `timeline.json`

### Step 4d: State Persistence

- Save audit JSON + Markdown report
- Update state.json (audit_count, latest_audit, latest_score, score_history)
- Append audit event to timeline.json
- Seed action-items.json from synthesis action_items

**Verify**: Run `/bc:audit` with Boris-only. It should:
- Produce valid audit JSON in `.boardclaude/audits/`
- Update state.json with correct counts
- Append an event to timeline.json
- Display composite score and top action items

---

## Phase 5: Agent Team Orchestration (Minutes 180-300)

**Goal**: Scale from 1 agent to 6 agents running in parallel via Agent Teams.

**Read**: `agents/boris.md` (as reference pattern — all agents follow the same structure).

### Step 5a: Agent Teams (preferred path)

Try Agent Teams first (env: `CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1`):
1. Create a team with 6 teammates (one per panel agent)
2. Each teammate gets: persona prompt + codebase scope + validation data + previous scores
3. Assign tasks to all teammates
4. Wait for all 6 to complete
5. Collect all `AgentEvaluation` JSONs
6. Run synthesis on all 6

### Step 5b: Sequential Subagent Fallback

If Agent Teams crashes twice within 30 minutes, switch immediately:
1. Spawn 6 sequential subagents (one per agent)
2. Each subagent gets identical context as the team approach
3. Collect results as each completes
4. Run synthesis identically

**The JSON output is identical either way.** Dashboard and downstream commands don't care how agents ran.

### Step 5c: Model Routing

Apply model routing from panel config:
- Boris, Cat, Thariq, Lydia → Opus 4.6
- Ado, Jason → Sonnet 4.5
- Synthesis → Sonnet 4.5 (subagent, not teammate)

**Verify**: Run `/bc:audit` with all 6 agents. All agent evaluations should:
- Return valid JSON
- Have scores in 0-100 range
- Include file references in strengths/weaknesses
- Produce a coherent synthesis with weighted composite

---

## Phase 6: Self-Audit #0 — Baseline (Minutes 300-360)

**Goal**: BoardClaude evaluates itself. This is iteration 0.

1. Ensure validation-runner has fresh `latest.json`
2. Run `/bc:audit --panel hackathon-judges`
3. Verify complete audit output:
   - `.boardclaude/audits/audit-{timestamp}.json` (valid `SynthesisReport`)
   - `.boardclaude/audits/audit-{timestamp}.md` (readable summary)
   - `.boardclaude/state.json` updated (audit_count=1, latest_score set)
   - `.boardclaude/timeline.json` has audit event
   - `.boardclaude/action-items.json` seeded from synthesis
4. Record the baseline composite score
5. Tag `v0.1.0` and push

**This is the M1 exit gate.** If Self-Audit #0 produces valid output, M1 is complete.

---

## M2 Build Sequence (Hours 6-18, lighter guidance)

After M1, Claude Code has enough context to work more autonomously. These are priorities, not step-by-step instructions.

### Priority 1: `/bc:fix` Command (Hours 6-11)
- Read `commands/fix.md` and `skills/fix-implementer/SKILL.md`
- Read `context/architecture/implementation-loop.md` for the full closed-loop spec
- Implement: read action-items.json → filter actionable → implement fix → run validation-runner → keep or revert → update ledger
- The validation gate is critical: no fix persists if validation regresses

### Priority 2: `/bc:init` Wizard (Hours 11-12)
- Read `commands/init.md`
- Implement template selection, directory creation, state initialization
- Test with `--template code-review` to verify non-hackathon panels work

### Priority 3: Persona Calibration (Hours 12-14)
- Run calibration audit on an external project (Compound Engineering Plugin)
- Compare agent scores against expectations
- Adjust persona prompts if scores are wildly off (>15 point deviation)

### Priority 4: First Fix Loop (Hours 14-18)
- Run `/bc:fix` on top 3 action items from Self-Audit #0
- Run validation-runner before and after
- Run `/bc:audit` again → Iteration 1
- Verify delta tracking works (iteration_delta in synthesis output)
- This completes the closed loop: audit → fix → validate → re-audit

**M2 Exit**: Tag `v0.2.0` when the full loop (audit → fix → re-audit) works end-to-end.

---

## First Prompt (Copy-Paste at Minute 12)

```
Read BUILD-SEQUENCE.md. This is your implementation guide for the next 6 hours.

Start with Phase 1: create dashboard/lib/types.ts with all TypeScript interfaces.
Reference context/architecture/schemas.md for the exact shapes. After types compile
cleanly, move to Phase 2 (verify plugin wiring), then Phase 3 (validation-runner).

Do not load files from context/judges/, context/features/, or context/strategy/
until explicitly needed. Follow the context loading rules in BUILD-SEQUENCE.md.

Goal: by hour 6, /bc:audit produces a valid self-audit JSON with all 6 agents.
```

---

## Checkpoints

| Time | Checkpoint | Pass Criteria | Fail Action |
|------|-----------|---------------|-------------|
| +30m | Types compile | `npx tsc --noEmit` = 0 errors | Fix type errors before proceeding |
| +45m | Plugin recognized | `/bc:audit` command resolves | Check plugin.json paths |
| +90m | Validation runs | `latest.json` produced | Check npm scripts exist |
| +180m | Single agent works | Boris produces valid JSON | Debug prompt/output format |
| +240m | Synthesis works | Full audit JSON saved | Check synthesis schema compliance |
| +300m | 6 agents work | All agents produce valid JSON | If Agent Teams crashes, switch to sequential |
| +360m | Self-Audit #0 | Complete audit in .boardclaude/ | Debug whatever failed, tag v0.1.0 when fixed |

---

## Anti-Patterns (Do NOT Do)

- **Do NOT build the dashboard during M1.** Dashboard is Track B, starting at M3.
- **Do NOT load all 23 context files.** Follow the context loading table above.
- **Do NOT optimize agent prompts during M1.** Get working output first, calibrate at M2.
- **Do NOT implement /bc:fork, /bc:compare, or /bc:merge during M1.** Those are M3.
- **Do NOT spend >30 minutes debugging Agent Teams.** Switch to sequential subagents.
- **Do NOT add features not in this document.** If it's not here, it goes in BACKLOG.md.
